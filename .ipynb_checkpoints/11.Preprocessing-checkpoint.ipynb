{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        label\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'label'])\n",
    "X = np.array(iris.drop(['label'], axis=1))\n",
    "y = np.array(iris['label'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.80916667 3.0575     3.7275     1.1825    ]\n",
      "[0.82036535 0.44453393 1.7439401  0.75029578]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.47393679,  1.22037928, -1.5639872 , -1.30948358],\n",
       "       [-0.13307079,  3.02001693, -1.27728011, -1.04292204],\n",
       "       [ 1.08589829,  0.09560575,  0.38562104,  0.28988568],\n",
       "       [-1.23014297,  0.77046987, -1.21993869, -1.30948358],\n",
       "       [-1.7177306 ,  0.32056046, -1.39196294, -1.30948358]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Scaling with Mean and STD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "print(scaler.mean_)\n",
    "print(scaler.scale_)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_train_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35451684, -0.57925837,  0.5576453 ,  0.02332414],\n",
       "       [-0.13307079,  1.67028869, -1.16259727, -1.17620281],\n",
       "       [ 2.30486738, -1.02916778,  1.81915651,  1.48941263],\n",
       "       [ 0.23261993, -0.35430366,  0.44296246,  0.42316645],\n",
       "       [ 1.2077952 , -0.57925837,  0.61498672,  0.28988568]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08823529, 0.66666667, 0.        , 0.04166667],\n",
       "       [0.41176471, 1.        , 0.0877193 , 0.125     ],\n",
       "       [0.70588235, 0.45833333, 0.59649123, 0.54166667],\n",
       "       [0.14705882, 0.58333333, 0.10526316, 0.04166667],\n",
       "       [0.02941176, 0.5       , 0.05263158, 0.04166667]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MinMax Scaling with Range\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_train_minmax[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52941176, 0.33333333, 0.64912281, 0.45833333],\n",
       "       [0.41176471, 0.75      , 0.12280702, 0.08333333],\n",
       "       [1.        , 0.25      , 1.03508772, 0.91666667],\n",
       "       [0.5       , 0.375     , 0.61403509, 0.58333333],\n",
       "       [0.73529412, 0.33333333, 0.66666667, 0.54166667]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_minmax = min_max_scaler.transform(X_test)\n",
    "X_test_minmax[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5974026 , 0.81818182, 0.14925373, 0.08      ],\n",
       "       [0.74025974, 1.        , 0.2238806 , 0.16      ],\n",
       "       [0.87012987, 0.70454545, 0.65671642, 0.56      ],\n",
       "       [0.62337662, 0.77272727, 0.23880597, 0.08      ],\n",
       "       [0.57142857, 0.72727273, 0.19402985, 0.08      ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MaxAbs Scaling with absolute Range\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "max_abs_scaler = MaxAbsScaler()\n",
    "X_train_maxabs = max_abs_scaler.fit_transform(X_train)\n",
    "X_train_maxabs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79220779, 0.63636364, 0.70149254, 0.48      ],\n",
       "       [0.74025974, 0.86363636, 0.25373134, 0.12      ],\n",
       "       [1.        , 0.59090909, 1.02985075, 0.92      ],\n",
       "       [0.77922078, 0.65909091, 0.67164179, 0.6       ],\n",
       "       [0.88311688, 0.63636364, 0.71641791, 0.56      ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_maxabs = max_abs_scaler.transform(X_test)\n",
    "X_test_maxabs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77577075, 0.60712493, 0.16864581, 0.03372916],\n",
       "       [0.77381111, 0.59732787, 0.2036345 , 0.05430253],\n",
       "       [0.76945444, 0.35601624, 0.50531337, 0.16078153],\n",
       "       [0.786991  , 0.55745196, 0.26233033, 0.03279129],\n",
       "       [0.78609038, 0.57170209, 0.23225397, 0.03573138]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer(norm='l2') # norm specifies the norm used to normalize the data\n",
    "X_train_normalized = normalizer.fit_transform(X_train)\n",
    "X_train_normalized[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73659895, 0.33811099, 0.56754345, 0.14490471],\n",
       "       [0.8068282 , 0.53788547, 0.24063297, 0.04246464],\n",
       "       [0.70600618, 0.2383917 , 0.63265489, 0.21088496],\n",
       "       [0.73350949, 0.35452959, 0.55013212, 0.18337737],\n",
       "       [0.76467269, 0.31486523, 0.53976896, 0.15743261]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_normalized = normalizer.transform(X_test)\n",
    "X_test_normalized[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LabelEncoding for Nominal\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_le = le.fit_transform(y)\n",
    "y_le[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py35/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OneHotEncoding for Ordinal\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit_transform([[1], [2], [3]]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py35/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [7., 8.],\n",
       "       [4., 5.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean')\n",
    "imp.fit_transform([[1, 2], [7, 8], [np.nan, np.nan]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  2.,  3.,  1.,  2.,  3.,  4.,  6.,  9.],\n",
       "       [ 1.,  4.,  5.,  6., 16., 20., 24., 25., 30., 36.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X = [[1,2,3], [4,5,6]]\n",
    "print(X)\n",
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
